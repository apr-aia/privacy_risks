{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, GRU, Bidirectional, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import f1_score\n",
        "import statistics"
      ],
      "metadata": {
        "id": "zZAaFt1abVYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract audio and lexcial features as explained in the multimodal target model\n",
        "x_audio_data = np.array([i[0] for i in df_list])  # Audio features\n",
        "x_text_data = np.array([i[1] for i in df_list])   # Text features\n",
        "y_data = np.array([i[2] for i in df_list])        # Depression labels (binary: 0 for control, 1 for depressed)\n",
        "unique_clip_ID_No = np.array([i[3] for i in df_list])  # Unique clip identifier\n",
        "session_number = np.array([i[4] for i in df_list])     # Session number"
      ],
      "metadata": {
        "id": "qaPXU5k-ibwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target model - lexical"
      ],
      "metadata": {
        "id": "U_neP6x2xaT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up parameters and data storage lists\n",
        "num_folds = 5\n",
        "speaker_ids = np.unique(session_number)\n",
        "k_fold = KFold(n_splits=num_folds, shuffle=True)\n",
        "training_index, testing_index, validation_index = [], [], []\n",
        "accuracies_best, loss_fold_best, F1_best, f1_MV_best_, accuracies_MV_best, session_list = [], [], [], [], [], []\n",
        "\n",
        "# Define a custom early stopping to restore the best weights\n",
        "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, patience=0, restore_path=''):\n",
        "        super(CustomEarlyStopping, self).__init__()\n",
        "        self.patience = patience\n",
        "        self.restore_path = restore_path\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        # Reset the wait counter.\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.best = np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        current_loss = logs.get('val_loss')\n",
        "        if np.less(current_loss, self.best):\n",
        "            self.best = current_loss\n",
        "            self.wait = 0\n",
        "            # Record the best weights if current results is better (less).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print('Restoring model weights from the end of the best epoch.')\n",
        "                self.model.load_weights(self.restore_path)\n",
        "\n",
        "# Split data into folds for cross-validation\n",
        "for fold_indexes_training, fold_indexes_test in k_fold.split(speaker_ids):\n",
        "    fold_testing = speaker_ids[fold_indexes_test]\n",
        "    fold_training = speaker_ids[fold_indexes_training]\n",
        "    testing_index.append(np.where(np.isin(session_number, fold_testing)))\n",
        "    training_index.append(np.where(np.isin(session_number, fold_training)))\n",
        "\n",
        "# Model training and evaluation\n",
        "for i in range(num_folds):\n",
        "    print(f'Fold number: {i + 1}')\n",
        "    x_train_text = x_text_data[training_index[i][0]]\n",
        "    y_train = y_data[training_index[i][0]]\n",
        "    x_test_text = x_text_data[testing_index[i][0]]\n",
        "    y_test = y_data[testing_index[i][0]]\n",
        "    session_no = np.unique(session_number[testing_index[i][0]])\n",
        "    print(f'Test session for this fold: {session_no}')\n",
        "    session_list.append(session_no)\n",
        "\n",
        "    # Model definition\n",
        "    n_gru_layers = 2\n",
        "    gru_layer_width = 252\n",
        "    lexical_input = Input(shape=(333, 768), name=\"lexical_input\")\n",
        "    x_l = lexical_input\n",
        "    for _ in range(n_gru_layers):\n",
        "        x_l = Bidirectional(GRU(gru_layer_width, return_sequences=True))(x_l)\n",
        "\n",
        "    x_l = GlobalAveragePooling1D()(x_l)\n",
        "    dense1 = Dense(128, activation='relu')(x_l)\n",
        "    output = Dense(2, activation='softmax')(dense1)\n",
        "    model = Model(inputs=lexical_input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping_custom = CustomEarlyStopping(patience=3)\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(x_train_text, y_train, validation_split=0.2, epochs=200, batch_size=64, callbacks=[early_stopping_custom])\n",
        "    loss, accuracy = model.evaluate(x_test_text, y_test)\n",
        "    print(f\"Test Loss: {loss}\")\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "    accuracies_best.append(accuracy)\n",
        "    loss_fold_best.append(loss)\n",
        "\n",
        "    # Predictions and F1 score\n",
        "    y_test_pred_best = [np.argmax(model.predict(np.array([x]), verbose=0)[0]) for x in x_test_text]\n",
        "    F1_score = f1_score(y_test, y_test_pred_best)\n",
        "    print(f\"F1 Score: {F1_score}\")\n",
        "    F1_best.append(F1_score)\n",
        "\n",
        "    # Majority vote accuracy\n",
        "    acc_MV_best, f1_MV_best = majority_vote(y_test, y_test_pred_best, unique_clip_ID_No[testing_index[i][0]])\n",
        "    print(f'Accuracy of majority vote: {acc_MV_best}')\n",
        "    print(f'F1 score of majority vote: {f1_MV_best}')\n",
        "    accuracies_MV_best.append(acc_MV_best)\n",
        "    f1_MV_best_.append(f1_MV_best)\n",
        "\n",
        "# Summary statistics\n",
        "print('--- Summary of Results ---')\n",
        "for test_set, loss, acc, f1 in zip(session_list, loss_fold_best, accuracies_best, F1_best):\n",
        "    print(f'Test set: {test_set}, Loss: {loss:.4f}, Accuracy: {acc:.4f}, F1 Score: {f1:.4f}')\n",
        "print(f'Average accuracy per 10 sec chunk: {np.mean(accuracies_best):.4f}, Std Dev: {statistics.stdev(accuracies_best):.4f}')\n",
        "print(f'Average F1 score per 10 sec chunk: {np.mean(F1_best):.4f}, Std Dev: {statistics.stdev(F1_best):.4f}')\n",
        "print(f'Average accuracy per clip: {np.mean(accuracies_MV_best):.4f}, Std Dev: {statistics.stdev(accuracies_MV_best):.4f}')\n",
        "print(f'Average F1 score per clip: {np.mean(f1_MV_best_):.4f}, Std Dev: {statistics.stdev(f1_MV_best_):.4f}')\n"
      ],
      "metadata": {
        "id": "p-I4vQTVbPm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}